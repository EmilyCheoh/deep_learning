(this["webpackJsonpreact-practice-app"]=this["webpackJsonpreact-practice-app"]||[]).push([[0],{174:function(e,t,a){e.exports=a(319)},317:function(e,t,a){},319:function(e,t,a){"use strict";a.r(t);var n=a(0),l=a.n(n),r=a(53),s=a.n(r),o=a(47),i=a(48),c=a(50),d=a(49),u=a(125),m=a(322),h=a(323),p=a(172),f=a(171),b=a(99),E=a(13),g=(l.a.Component,a(317),{labels:[],datasets:[{label:"Number of Cases",data:[],fill:!1,borderColor:"#DC143C"},{label:"Number of Tests Conducted",data:[],fill:!1,borderColor:"#006400"}]}),v={labels:["Jan","Feb","Mar","Apr","May","Jun"],datasets:[{label:"Number of Daily Confirmed Cases",data:[2,1,2,1,1,1],fill:!1,borderColor:"#DC143C"}]},y={labels:["Jan","Feb","Mar","Apr","May","Jun"],datasets:[{label:"Number of Tests Conducted Daily",data:[4,5,7,10,9,10],fill:!1,borderColor:"#006400"}]},C={labels:["Jan","Feb","Mar","Apr","May","Jun"],datasets:[{label:"Number of Daily Confirmed Cases",data:[1,3,6,10,20,36],backgroundColor:"#DC143C",borderColor:"DC143C",borderWidth:1,hoverBackgroundColor:"#CD5C5C",hoverBorderColor:"#CD5C5C",display:!0,labelString:"Number of Daily Confirmed Cases",lineHeight:1.2,fontColor:"#666",fontFamily:"'Helvetica Neue', 'Helvetica', 'Arial', sans-serif",fontSize:12,fontStyle:"normal",padding:4}]},w={labels:["Jan","Feb","Mar","Apr","May","Jun"],datasets:[{label:"Number of Daily Tests Conducted Daily",data:[1,3,6,10,20,36],backgroundColor:"#006400",borderColor:"#006400",borderWidth:1,hoverBackgroundColor:"#8FBC8F",hoverBorderColor:"#8FBC8F",display:!0,labelString:"Number of Daily Confirmed Cases",lineHeight:1.2,fontColor:"#666",fontFamily:"'Helvetica Neue', 'Helvetica', 'Arial', sans-serif",fontSize:12,fontStyle:"normal",padding:4}]},T={datasets:[{data:[10,20,30],backgroundColor:["#DC143C","#006400","#00008B","#E7E9ED","#36A2EB"],label:"Effects of Govt Orders in June 2020, IL"}],labels:["Number of Cases","Tests Conducted","Unemployment Claims"]},N=["Project Overview","Motivation","Methods","Results"],B=[{name:N[0],isActive:!0},{name:N[1],isActive:!1},{name:N[2],isActive:!1},{name:N[3],isActive:!1}],M=function(e){Object(c.a)(a,e);var t=Object(d.a)(a);function a(){return Object(o.a)(this,a),t.apply(this,arguments)}return Object(i.a)(a,[{key:"render",value:function(){return l.a.createElement("ul",{className:"nav nav-tabs"},B.map(function(e){return l.a.createElement(S,{data:e,isActive:this.props.activeTab===e,handleClick:this.props.changeTab.bind(this,e)})}.bind(this)))}}]),a}(l.a.Component),S=function(e){Object(c.a)(a,e);var t=Object(d.a)(a);function a(){return Object(o.a)(this,a),t.apply(this,arguments)}return Object(i.a)(a,[{key:"render",value:function(){return l.a.createElement("li",{onClick:this.props.handleClick,className:this.props.isActive?"active":null},l.a.createElement("a",{href:"#"},this.props.data.name))}}]),a}(l.a.Component),A=function(e){Object(c.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(o.a)(this,a),(n=t.call(this,e)).state={error:null,isLoaded:!1,cases:[],tested:[],date:[],daily_confirmed:[]},n}return Object(i.a)(a,[{key:"componentDidMount",value:function(){var e=this;fetch("http://127.0.0.1:5000/case19",{mode:"cors"}).then((function(e){return e.json()})).then((function(t){for(var a=[],n=[],l=[],r=[],s=[],o=0;o<t.length;o++)a.push(t[o].case),n.push(t[o].date.substr(4,2)+"-"+t[o].date.substr(6,2)),l.push(t[o].positiveIncrease),r.push(t[o].totalTestResults),s.push(t[o].totalTestResultsIncrease);e.setState({isLoaded:!0,cases:a,date:n,tested:r,daily_confirmed:l,daily_tested:s})}),(function(t){e.setState({isLoaded:!0,error:t})}))}},{key:"render",value:function(){var e=this.state,t=(e.error,e.isLoaded,e.cases),a=e.date,n=e.daily_confirmed,r=e.tested,s=e.daily_tested;return g.datasets[0].data=t,g.datasets[1].data=r,g.labels=a,v.datasets[0].data=n,v.labels=a,C.datasets[0].data=n,C.labels=a,y.labels=a,y.datasets[0].data=s,w.labels=a,w.datasets[0].data=s,T.datasets[0].data=[t[t.length-1],r[r.length-1],2570646],l.a.createElement(m.a,{className:"content"},this.props.activeTab.name===N[0]?l.a.createElement(m.a,{fluid:!0},l.a.createElement("section",{className:"panel panel-danger"},l.a.createElement("h2",{className:"panel-heading"},"Project Overview"),l.a.createElement("p",{className:"panel-body"},"Sentiment analysis has been a critical task of natural language processing (NLP). In this project, we focus on analyzing sentiments of short movies reviews using Bi-LSTM models. We construct four variations of Bi-LSTM models, namely Word2vec-based Bi-LSTM, Word2vec-based Bi-LSTM with Attention model, BERT-based Bi-LSTM, and BERT-based Bi-LSTM with Attention model, and compare the performance of our models with other popular NLP models. Through our experiments, we find that the BERT-based Bi-LSTM with Attention model achieves the best overall results.")),l.a.createElement(m.a,{fluid:!0},l.a.createElement("div",{className:"spacing"}),l.a.createElement(u.b,{id:"line_graph",data:g}),l.a.createElement("div",{className:"graphspacing"}),l.a.createElement(u.a,{data:T}),l.a.createElement("div",{className:"graphspacing"}))):null,this.props.activeTab.name===N[1]?l.a.createElement(m.a,{fluid:!0},l.a.createElement("section",{className:"panel panel-danger"},l.a.createElement("h2",{className:"panel-heading"},"Motivation"),l.a.createElement("p",{className:"panel-body"},"The prevalence of the internet greatly propagates the amount of user-generated contents. As user-generated contents usually reflect the thinkings of the authors, they contain valuable information that can be helpful to multiple stakeholders. For example, a movie producer might want to know how audiences are reacting to her latest movie by reading through the comments and reviews online. It is reasonable to argue that such an approach is not efficient enough if there are thousands of reviews available, and it is natural to think of whether it is possible to use deep learning techniques to systematically analyze such information on a large scale. Hence, for this project, we propose to test the performance of various deep learning models on predicting sentiments of movie reviews, and we want to focus on short reviews in particular because they are usually hard to train due to the limited length. Another challenge of analyzing short reviews is that they often contain a lot of verbal language and may not be written in standard English grammar."))):null,this.props.activeTab.name===N[2]?l.a.createElement(m.a,{fluid:!0},l.a.createElement("section",{className:"panel panel-danger"},l.a.createElement("h2",{className:"panel-heading"},"Methods"),l.a.createElement("p",{className:"panel-body"},l.a.createElement("p",null,"We train our models on the IMDB movie sentiment dataset provided by [4]. The dataset contains 50,000 binary labeled movie reviews for training and testing, with the reviews equally divided into training and testing sets. 50,000 unlabeled data are also included for unsupervised training."),l.a.createElement("p",null,"We analyze the dataset by examining the distribution of text length. As shown in figure 2.1, the majority of  reviews are within the length of 250 words. As we focus on short movie reviews for the project, we decide to use 200 as the maximum text length to filter out long reviews. We then perform data cleansing for feature construction by decapitalizing all the letters and removing punctuations and stopwords. We also remove words with low frequency because they may be typos and do not carry significant meaning.")),l.a.createElement("p",{className:"panel-body"},l.a.createElement("p",null,"After the preprocessing is done, we experiment with two different models to generate word embeddings that are later used as the input of our deep learning models. We first use the Word2vec model. We specify to use the Skip-gram method to train, which predicts the word based on relevant context. We choose Skip-gram over CBOW because it is good at representing rare words and has higher accuracy."),l.a.createElement("p",null,"We also use the BERT model to generate sentence embeddings as it is a relatively new model and is good at resolving polysemy, so we wonder if using word embeddings from the BERT model can improve accuracy. We use the BERT base model with 12 layers. Although it is possible to use the output of any layer as the word embeddings for later use, we find that the output of the 11th layer produces the best results. If we use the output from earlier layers, the model may not be sufficiently trained; if we directly use the output from the last layer, it would be too similar to the original text. "),l.a.createElement("p",null,"We then construct a Bi-LSTM model with 128 neurons for training, with each neuron defining a forward LSTM structure and a reverse LSTM structure. We then concatenate their outputs, and pass it to the next layer of the Bi-LSTM model. "),l.a.createElement("p",null,"To examine whether combining the Attention model with Bi-LSTM can improve accuracy, we pass the result of the last layer of the Bi-LSTM model to an Attention model. We then apply the tanh activation function to the output, multiply it with the weight vector, calculate the softmax, and pass the final result to the fully connected layer.")))):null,this.props.activeTab.name===N[3]?l.a.createElement(m.a,{fluid:!0},l.a.createElement("section",{className:"panel panel-danger"},l.a.createElement("h2",{className:"panel-heading"},"Results"),l.a.createElement("p",{className:"panel-body"},l.a.createElement("p",null,"Because we're performing binary classification, our predicting results belong to one of the following four outcomes: true positive, true negative), false positive, and false negative. Therefore, we measure performance by four metrics: Area under the ROC Curve (AUC), Accuracy (ACC), precision (PRE), and recall (REC). Ideally, we would like to maximize all of the above metrics. "),l.a.createElement("p",null,"We compare both our Word2Vec-based model and BERT-based model against four other commonly used deep learning NLP models such as textCNN and CharCNN, as well as a single directional LSTM model. The results are shown in the following table:"),l.a.createElement("table",{className:"results"},l.a.createElement("tr",null,l.a.createElement("th",null,"Model"),l.a.createElement("th",null,"ACC"),l.a.createElement("th",null,"AUC"),l.a.createElement("th",null,"PRE"),l.a.createElement("th",null,"REC")),l.a.createElement("tr",null,l.a.createElement("td",null,"TextCNN"),l.a.createElement("td",null,"0.8616"),l.a.createElement("td",null,"0.9332"),l.a.createElement("td",null,"0.8726"),l.a.createElement("td",null,"0.8503")),l.a.createElement("tr",null,l.a.createElement("td",null,"CharCNN"),l.a.createElement("td",null,"0.8379"),l.a.createElement("td",null,"0.9176"),l.a.createElement("td",null,"0.8383"),l.a.createElement("td",null,"0.8381")),l.a.createElement("tr",null,l.a.createElement("td",null,"LSTM"),l.a.createElement("td",null,"0.8571"),l.a.createElement("td",null,"0.9201"),l.a.createElement("td",null,"0.8626"),l.a.createElement("td",null,"0.8120")),l.a.createElement("tr",null,l.a.createElement("td",null,"Word2Vec-based Bi-LSTM"),l.a.createElement("td",null,"0.8451"),l.a.createElement("td",null,"0.9064"),l.a.createElement("td",null,"0.8975"),l.a.createElement("td",null,"0.8029")),l.a.createElement("tr",null,l.a.createElement("td",null,"Word2Vec-based Bi-LSTM+Attention"),l.a.createElement("td",null,"0.8762"),l.a.createElement("td",null,"0.9381"),l.a.createElement("td",null,"0.9077"),l.a.createElement("td",null,"0.8615")),l.a.createElement("tr",null,l.a.createElement("td",null,"BERT-based Bi-LSTM"),l.a.createElement("td",null,"0.8841"),l.a.createElement("td",null,"0.9293"),l.a.createElement("td",null,"0.9257"),l.a.createElement("td",null,"0.8592")),l.a.createElement("tr",null,l.a.createElement("td",null,"BERT-based Bi-LSTM+Attention"),l.a.createElement("td",null,"0.9343"),l.a.createElement("td",null,"0.9506"),l.a.createElement("td",null,"0.9517"),l.a.createElement("td",null,"0.9239")))))):null)}}]),a}(l.a.Component),L=function(e){Object(c.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(o.a)(this,a),(n=t.call(this)).handleClick=function(e){n.setState({activeTab:e})},n.state={activeTab:B[0]},n}return Object(i.a)(a,[{key:"render",value:function(){return l.a.createElement(m.a,{fluid:!0},l.a.createElement(M,{activeTab:this.state.activeTab,changeTab:this.handleClick}),l.a.createElement(A,{activeTab:this.state.activeTab}))}}]),a}(l.a.Component);function k(){return l.a.createElement(m.a,{fluid:!0,className:"header-image-style"},l.a.createElement(h.a,{className:"text-center transparent-0 header-text"},l.a.createElement(h.a.Body,null,l.a.createElement(h.a.Title,{className:"mainheader-text",as:"h1"},"Testing the Performances of Variations of the Bi-LSTM model on Sentiment Analysis"),l.a.createElement("div",{className:"info"},l.a.createElement(h.a.Text,{className:"subheader-text",as:"h4"},"Emily Qiao, Jianzhe Xiao"),l.a.createElement(h.a.Text,{className:"subheader-text",as:"h4"},"contact email: emqiao@gmail.com"),l.a.createElement(h.a.Text,{className:"subheader-text",as:"h4"},"Final project for CS 496 Deep Learning, taught by Professor Bryan Pardo"),l.a.createElement(h.a.Text,{className:"subheader-text link",as:"h4"},l.a.createElement("a",{href:"https://github.com/EmilyCheoh/deep_learning/blob/main/final_paper.pdf"},"Link to final paper"))))),l.a.createElement(m.a,{fluid:!0},l.a.createElement(L,null)))}var x=function(){return l.a.createElement(k,null)};a(318);s.a.render(l.a.createElement(x,null),document.getElementById("root"))}},[[174,1,2]]]);
//# sourceMappingURL=main.f5869ab8.chunk.js.map